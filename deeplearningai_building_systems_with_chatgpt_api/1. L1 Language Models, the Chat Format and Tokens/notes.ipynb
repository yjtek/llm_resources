{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Steps to processing input\n",
    "    - Preprocess to check for hate/restricted content \n",
    "    - Process input to identify type of query\n",
    "        - Is it complaint, query etc\n",
    "    - Get response\n",
    "    - Check response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do LLMs work?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an LLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training process\n",
    "    - <prompt> I love eating </prompt> _ _ _ _ _\n",
    "    - Model is trained to fill in the blanks `_`\n",
    "    - Model training is supervised i.e. use restaurant review text iteratively as feature, next word as labels\n",
    "        - \"I really like the chicken rice...\"\n",
    "        - Input 1: I really like the | Output 1: chicken\n",
    "        - Input 2: I really like the chicken | Output 2: rice\n",
    "        - ...\n",
    "\n",
    "- This describes the **base LLM**. While this works to an extent, the obvious downside is that word occurences learnt in this manner has issues with context\n",
    "    - Let's say we ask the LLM  \"what is the capital of france?\". If the model is trained on internet data, then it may feasibly end up referring to some list of trivia questions, and start returning MORE questions to you (i.e. \"what is the largest city in france?\" etc), which is obviously not the intent \n",
    "    - So we want an **instruction tuned LLM**, something that will respond to the question \"what is the capital of france?\" with \"Paris\", and not ask more questions\n",
    "\n",
    "- To get an **instruction tuned LLM**:\n",
    "    - Train a **base LLM**\n",
    "    - Train the model further by finetuning using examples where output follows an input instruction\n",
    "    - Obtain human ratings of quality of different LLM outputs. This should be rated on a list of criteria (helpful? honest? harmful?)\n",
    "    - Tune the LLM further to increase probability that it generates more highly rated outputs (using RLHF; reinforcement learning from human feedback)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Token vs Next Word Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some seemingly \"easy\" tasks may fail with chat GPT\n",
    "    - Reverse \"lollipop\" returns `ppilolol`, which is nonsense\n",
    "    - It does not work because of how the processing in ChatGPT works; \n",
    "        - ChatGPT uses next-token prediction\n",
    "        - lollipop is preprocessed to `l` `oll` `ipop`\n",
    "        - Hence it ends up not being able to reverse the word, because of how the preprocessing is done\n",
    "        - However, you can add `-` between the letters to make it work, because then chatGPT has an easier time tokenising the word\n",
    "\n",
    "- Different models will accept a different number of tokens as context, and as of now chatgpt takes ~4000 tokens\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify the role of a system as a **system** message, before asking your questions with **user** message\n",
    "```\n",
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who\\\n",
    " responds in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"write me a very short poem\\\n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
